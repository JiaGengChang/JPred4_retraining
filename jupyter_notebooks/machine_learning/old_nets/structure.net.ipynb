{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure to structure net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import core modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load previously calculated sequence to structure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('/homes/2472402/data/layer1.model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training data as 1 dataframe per sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('/homes/2472402/data/linearized_train_sequences.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate predictions from dssp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>R</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>E</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>...</th>\n",
       "      <th>K</th>\n",
       "      <th>M</th>\n",
       "      <th>F</th>\n",
       "      <th>P</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "      <th>W</th>\n",
       "      <th>Y</th>\n",
       "      <th>V</th>\n",
       "      <th>dssp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>16</th>\n",
       "      <th>16</th>\n",
       "      <th>16</th>\n",
       "      <th>16</th>\n",
       "      <th>16</th>\n",
       "      <th>16</th>\n",
       "      <th>16</th>\n",
       "      <th>16</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119203</td>\n",
       "      <td>0.952574</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.119203</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>0.047426</td>\n",
       "      <td>0.952574</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993307</td>\n",
       "      <td>0.047426</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.047426</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>0.119203</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>0.119203</td>\n",
       "      <td>0.047426</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.006693</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.119203</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.006693</td>\n",
       "      <td>0.047426</td>\n",
       "      <td>0.982014</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.047426</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>0.119203</td>\n",
       "      <td>0.952574</td>\n",
       "      <td>0.006693</td>\n",
       "      <td>0.047426</td>\n",
       "      <td>0.952574</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 341 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   R   N   D   C   Q   E   G   H   I  ...         K         M         F  \\\n",
       "    0   0   0   0   0   0   0   0   0   0  ...        16        16        16   \n",
       "0 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...  0.119203  0.952574  0.268941   \n",
       "1 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...  0.993307  0.047426  0.017986   \n",
       "2 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...  0.268941  0.017986  0.119203   \n",
       "3 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...  0.017986  0.268941  0.119203   \n",
       "4 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...  0.268941  0.268941  0.047426   \n",
       "\n",
       "          P         S         T         W         Y         V dssp  \n",
       "         16        16        16        16        16        16       \n",
       "0  0.268941  0.268941  0.119203  0.017986  0.047426  0.952574    -  \n",
       "1  0.017986  0.268941  0.047426  0.731059  0.731059  0.017986    -  \n",
       "2  0.017986  0.119203  0.047426  0.017986  0.731059  0.006693    -  \n",
       "3  0.017986  0.017986  0.268941  0.006693  0.047426  0.982014    -  \n",
       "4  0.017986  0.119203  0.952574  0.006693  0.047426  0.952574    -  \n",
       "\n",
       "[5 rows x 341 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = [df.dssp for df in data]\n",
    "X = [df.iloc[:,:-1] for df in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [model.predict(Xi) for Xi in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save predictions made by layer 1 along with ground truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a49f1826dbaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_actual\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/homes/2472402/data/layer.1.predictions.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "pickle.dump([Y, y_actual], open('/homes/2472402/data/layer.1.predictions.pkl', 'wb'), protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and do one hot encoding of actual dssp info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "[Y_pred, Y_actual] = pickle.load(open('/homes/2472402/data/layer.1.predictions.pkl', 'rb'))\n",
    " \n",
    "# convert prediction to actual predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform one hot encoding of y_actual in same column order as that defined in one hot encoding of layer 1 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore', categories = [['H','E','-']], sparse=False)\n",
    "\n",
    "def one_hot(y,enc):\n",
    "    y_as_col = y.values.reshape(-1,1)\n",
    "    y_one_hot = pd.DataFrame(enc.fit_transform(y_as_col))\n",
    "    return y_one_hot\n",
    "\n",
    "Y_actual = [one_hot(y_actual,enc) for y_actual in Y_actual]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate sliding window and convert to 1 row df for every sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to add padding of #FLANK rows to the top and bottom of dataframe. flank = 8 for layer 1 (seq to struct) and flank = 9 for layer 2 (struct to struct)\n",
    "def padding_operation(pred, flank):\n",
    "    # create a numpy array with 21 NaNs\n",
    "    pad_np_array = np.hstack((np.repeat(np.nan,3)))\n",
    "    # convert numpy array into pd Series so we can create dataframe based on it\n",
    "    pad_row = pd.Series(pad_np_array)\n",
    "    # create empty dataframe and add the NaN rows to it\n",
    "    pad_df = pd.DataFrame()\n",
    "    for _ in range(flank):\n",
    "        pad_df = pad_df.append(pad_row, ignore_index=True)\n",
    "    # create a copy of profile which i will now modify\n",
    "    df = pd.DataFrame(pred)\n",
    "    # add padding to above and below dataframes\n",
    "    padded_df = pd.concat([pad_df, df, pad_df], ignore_index=True)\n",
    "    return padded_df\n",
    "\n",
    "# function returns a list of windows (variable name patterns). flank argument is same as above. takes in the padded_df from padding_operation()\n",
    "def sliding_operation(padded_df, flank):\n",
    "    # Using iloc based indexing. i.e. 'location based indexing' cf label based indexing\n",
    "    # idx of first amino acid of sequence in padded dataframe \n",
    "    seqStartIdx = flank \n",
    "    # idx of last amino acid of sequence in padded dataframe\n",
    "    seqEndIdx = padded_df.shape[0]-flank\n",
    "    # create a list of dataframes which we will put individual windows into. this list of patterns should span across samples\n",
    "    patterns = []\n",
    "    for seqIdx in range(seqStartIdx, seqEndIdx): # for each amino acid sequence / centroid of window\n",
    "        # define start and end index of window given position of center residue\n",
    "        winStartIdx = seqIdx - flank\n",
    "        winEndIdx = seqIdx + flank + 1\n",
    "        # again using location based indexing with .iloc[]\n",
    "        pattern = padded_df.iloc[winStartIdx:winEndIdx, :]\n",
    "        patterns.append(pattern)\n",
    "    return patterns\n",
    "\n",
    "# function to collapse rows in df into a single row dataframe. \n",
    "def linearize(df):\n",
    "    ndf = df.T.unstack().to_frame().T\n",
    "    ndf.columns = list(range(len(ndf.columns))) # do this so as to avoid having to rename columns later on\n",
    "    return ndf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapper code calling two functions above on each PSSM dataframe to generate patterns from all dataframes\n",
    "THIS CODE IS TIME CONSUMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-dd6fa1fb1b67>\u001b[0m in \u001b[0;36mlinearize\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlinearize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mndf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mndf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# do this so as to avoid having to rename columns later on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mndf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sandbox/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5476\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5477\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5478\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5479\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5480\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sandbox/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sandbox/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   5905\u001b[0m                 \u001b[0;31m# Check for overflows if we should actually be uint64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5906\u001b[0m                 \u001b[0;31m# xref GH#35481\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5907\u001b[0;31m                 \u001b[0malt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5909\u001b[0m                     \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sandbox/lib/python3.9/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# keep patterns in their sequencse. list of dataframes of linearized 3 state predictions\n",
    "Y_patterns = []\n",
    "for y_pred in Y_pred:\n",
    "    padded_pf = padding_operation(y_pred, flank = 9)\n",
    "    patterns = sliding_operation(padded_pf, flank = 9)\n",
    "    linearized_patterns = [linearize(pattern) for pattern in patterns]\n",
    "    df = pd.concat(linearized_patterns, ignore_index=True)\n",
    "    Y_patterns.append(df)\n",
    "\n",
    "len(Y_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save as input for layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([Y_patterns,Y_actual], open('/homes/2472402/data/layer2.input.pkl', 'wb'), protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load input for layer 2 and train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling it Y_patterns because Y_pred is a different thing (see above)\n",
    "[Y_patterns,Y_actual] = pickle.load(open('/homes/2472402/data/layer2.input.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1 of 2: Run this code if removing rows with NaN (do not run this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [np.logical_not(y.isnull().any(axis=1)) for y in Y_patterns]\n",
    "X_ls = [y.loc[i] for (y, i) in zip(Y_patterns, idx)]\n",
    "X_in = pd.concat(X_ls, axis='rows')\n",
    "Y_ls = [y.loc[i] for (y, i) in zip(Y_actual, idx)]\n",
    "Y_in = pd.concat(Y_ls, axis='rows')\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_in, Y_in, train_size = 10000, test_size = 2000, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2 of 2: Run this block if filling NaN with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat(Y_patterns, axis='rows')\n",
    "# replace nan with 0\n",
    "X.fillna(0, inplace=True)\n",
    "Y = pd.concat(Y_actual, axis='rows')\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, train_size = 6000, test_size = 1000, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the second layer of networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /homes/2472402/data/layer2.model/assets\n",
      "Minimum validation loss: 0.6638691425323486\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define a simple model for sequence to structure prediction\n",
    "model2 = keras.Sequential([\n",
    "    layers.Dense(units=100, activation='sigmoid', input_shape=[57]),\n",
    "    layers.Dense(units=3, activation='softmax')\n",
    "])\n",
    "\n",
    "# compile mode. note metrics argument is left out\n",
    "model2.compile(\n",
    "    optimizer='sgd', \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model2.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_valid, Y_valid),\n",
    "    batch_size=128, # not optimised\n",
    "    epochs=250, # same as jnet v2.3.1\n",
    "    verbose=0, # suppress output since we'll plot the curves\n",
    ")\n",
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "model2.save('/homes/2472402/data/layer2.model')\n",
    "\n",
    "# review results\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot()\n",
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sandbox]",
   "language": "python",
   "name": "conda-env-sandbox-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

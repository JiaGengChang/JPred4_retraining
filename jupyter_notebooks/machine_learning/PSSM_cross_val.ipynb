{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de8cb0fb-5b7e-4fad-81ce-351cf652efd1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PSSM cross validation notebook\n",
    "\n",
    "Script largely adapted from HMM_cross_val.ipynb\n",
    "\n",
    "It parses file in the same way as HMM_cross_val.ipynb, which is different from that of cross_val_old.ipynb\n",
    "\n",
    "I created this notebook to run checks so that the equivalent .py script will not crash when submitted to the scheduler\n",
    "\n",
    "The actual script used to run cross validation is stored in /cluster/gjb_lab/2472402/scripts/pssm_cross_val.py\n",
    "\n",
    "Last changes made: 07 Aug 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea1e4ec-6335-4349-936f-ef805c434177",
   "metadata": {},
   "source": [
    "1. Declare modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e92d6e4-7251-4a5e-909c-55a16d2af34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import path\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "# this function is copied from HMM.ipynb\n",
    "# array: numpy array\n",
    "# flank: positive integer\n",
    "def sliding_window(array, flank):\n",
    "    assert flank > 0\n",
    "    assert type(array) is np.ndarray\n",
    "    assert np.logical_not(np.isnan(np.sum(array)))\n",
    "    nrow = array.shape[0]\n",
    "    assert nrow > 0\n",
    "    ncol = array.shape[1]\n",
    "    assert ncol > 0\n",
    "    res = np.empty(shape=(nrow, (2*flank+1)*ncol))\n",
    "    res[:] = np.nan\n",
    "    for i in list(range(0,nrow)):\n",
    "        s, e = i-flank, i+flank+1\n",
    "        k = 0;\n",
    "        for j in list(range(s,e)):\n",
    "            if (j < 0 or j >= nrow):\n",
    "                res[i, k:k+ncol] = 0\n",
    "            else:\n",
    "                assert np.logical_not(np.isnan(np.sum(array[j])))\n",
    "                assert array[j].shape == (ncol,)\n",
    "                res[i, k:k+ncol] = array[j]\n",
    "            k += ncol\n",
    "    assert np.logical_not(np.isnan(np.sum(res)))\n",
    "    assert res.shape == (nrow, (2*flank+1)*ncol)\n",
    "    return res\n",
    "\n",
    "# this function rounds predictions into 1 and 0s\n",
    "def argmax(arr):\n",
    "    n, c = arr.shape\n",
    "    assert c == 3\n",
    "    assert type(arr) is np.ndarray\n",
    "    assert np.logical_not(np.isnan(np.sum(arr)))\n",
    "    res = np.empty(shape=(n,c))\n",
    "    res[:] = np.nan\n",
    "    for i in list(range(0,n)):\n",
    "        max_idx = np.argmax(arr[i])\n",
    "        if max_idx == 0:\n",
    "            res[i] = np.array([1, 0, 0])\n",
    "        elif max_idx == 1:\n",
    "            res[i] = np.array([0, 1, 0])\n",
    "        else:\n",
    "            assert max_idx == 2\n",
    "            res[i] = np.array([0, 0, 1])\n",
    "    assert np.logical_not(np.isnan(np.sum(res)))\n",
    "    return res\n",
    "\n",
    "def get_dssp(ID):\n",
    "    path = '/homes/adrozdetskiy/Projects/JnetDatasets/DSSP_out/' + ID + '.sec'\n",
    "    ls = list(pd.read_csv(path).loc[0].values)\n",
    "    ls[0] = ls[0][-1:] # remove the DSSP: part from first list item\n",
    "    res = np.empty(shape=(len(ls),3))\n",
    "    res[:] = np.nan\n",
    "    for i in range(0,len(ls)):\n",
    "        if ls[i] == 'H':\n",
    "            res[i] = np.array([1,0,0])\n",
    "        else:\n",
    "            if ls[i] == 'E' or ls[i] == 'B':\n",
    "                res[i] = np.array([0,1,0])\n",
    "            else:\n",
    "                assert ls[i] != None\n",
    "                res[i] = np.array([0,0,1])\n",
    "    assert not np.isnan(np.sum(res))\n",
    "    return res\n",
    "\n",
    "def eprint(*args, **kwargs):\n",
    "    print(*args, file=sys.stderr, **kwargs)\n",
    "    \n",
    "\n",
    "# first make sure that output path is valid, otherwise computation will go to waste\n",
    "out_path = '/cluster/gjb_lab/2472402/outputs/pssm_cross_val/'\n",
    "assert path.exists(out_path)\n",
    "assert out_path[-1] == '/'\n",
    "\n",
    "\n",
    "# path to training and validation examples\n",
    "paths = [\"/homes/adrozdetskiy/Projects/JnetDatasets/Jnet_training_output_v2/cross-val%d/\" % num for num in range(1,8)]\n",
    "\n",
    "# sequence dictionary or sd. need this to retrieve dssp information\n",
    "sd = pickle.load(open('/cluster/gjb_lab/2472402/data/cross-val/cross_val_dict.pkl','rb')) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d090f1-dc53-46fd-b766-ada2edebf72b",
   "metadata": {},
   "source": [
    "2. actual training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef5c88a3-16c2-40e0-963a-90d7aa6f1101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Commencing fold 1 of cross validation at 08/07/21 20:11:10\n",
      "Fitting layer 1 model. 20:11:12\n",
      "Calculating layer 1 predictions. 20:11:56\n",
      "Fitting layer 2 model. 20:11:59\n",
      "Saving results to /cluster/gjb_lab/2472402/outputs/pssm_cross_val/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /cluster/gjb_lab/2472402/outputs/pssm_cross_val/fold1_model1/assets\n",
      "INFO:tensorflow:Assets written to: /cluster/gjb_lab/2472402/outputs/pssm_cross_val/fold1_model2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished fold 1 of cross validation at 08/07/21 20:12:48\n",
      "\n",
      "Commencing fold 2 of cross validation at 08/07/21 20:12:48\n",
      "Fitting layer 1 model. 20:12:49\n",
      "Calculating layer 1 predictions. 20:13:33\n",
      "Fitting layer 2 model. 20:13:35\n",
      "Saving results to /cluster/gjb_lab/2472402/outputs/pssm_cross_val/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /cluster/gjb_lab/2472402/outputs/pssm_cross_val/fold2_model1/assets\n",
      "INFO:tensorflow:Assets written to: /cluster/gjb_lab/2472402/outputs/pssm_cross_val/fold2_model2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished fold 2 of cross validation at 08/07/21 20:14:24\n",
      "\n",
      "Commencing fold 3 of cross validation at 08/07/21 20:14:24\n",
      "Fitting layer 1 model. 20:14:25\n",
      "Calculating layer 1 predictions. 20:15:15\n",
      "Fitting layer 2 model. 20:15:17\n",
      "Saving results to /cluster/gjb_lab/2472402/outputs/pssm_cross_val/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /cluster/gjb_lab/2472402/outputs/pssm_cross_val/fold3_model1/assets\n",
      "INFO:tensorflow:Assets written to: /cluster/gjb_lab/2472402/outputs/pssm_cross_val/fold3_model2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished fold 3 of cross validation at 08/07/21 20:16:05\n",
      "\n",
      "Commencing fold 4 of cross validation at 08/07/21 20:16:05\n",
      "Fitting layer 1 model. 20:16:06\n",
      "Calculating layer 1 predictions. 20:16:51\n",
      "Fitting layer 2 model. 20:16:54\n",
      "Saving results to /cluster/gjb_lab/2472402/outputs/pssm_cross_val/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /cluster/gjb_lab/2472402/outputs/pssm_cross_val/fold4_model1/assets\n",
      "INFO:tensorflow:Assets written to: /cluster/gjb_lab/2472402/outputs/pssm_cross_val/fold4_model2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished fold 4 of cross validation at 08/07/21 20:17:43\n",
      "\n",
      "Commencing fold 5 of cross validation at 08/07/21 20:17:43\n",
      "Fitting layer 1 model. 20:17:44\n",
      "Calculating layer 1 predictions. 20:18:32\n",
      "Fitting layer 2 model. 20:18:35\n",
      "Saving results to /cluster/gjb_lab/2472402/outputs/pssm_cross_val/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /cluster/gjb_lab/2472402/outputs/pssm_cross_val/fold5_model1/assets\n",
      "INFO:tensorflow:Assets written to: /cluster/gjb_lab/2472402/outputs/pssm_cross_val/fold5_model2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished fold 5 of cross validation at 08/07/21 20:19:22\n",
      "\n",
      "Commencing fold 6 of cross validation at 08/07/21 20:19:22\n",
      "Fitting layer 1 model. 20:19:24\n",
      "Calculating layer 1 predictions. 20:20:12\n",
      "Fitting layer 2 model. 20:20:15\n",
      "Saving results to /cluster/gjb_lab/2472402/outputs/pssm_cross_val/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /cluster/gjb_lab/2472402/outputs/pssm_cross_val/fold6_model1/assets\n",
      "INFO:tensorflow:Assets written to: /cluster/gjb_lab/2472402/outputs/pssm_cross_val/fold6_model2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished fold 6 of cross validation at 08/07/21 20:20:59\n",
      "\n",
      "Commencing fold 7 of cross validation at 08/07/21 20:20:59\n",
      "Fitting layer 1 model. 20:21:00\n",
      "Calculating layer 1 predictions. 20:21:48\n",
      "Fitting layer 2 model. 20:21:51\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b70674663adc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0meprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fitting layer 2 model. %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%H:%M:%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     history2 = model2.fit(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mX_train_2_stacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_stacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# y_train is unchanged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_valid_2_stacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid_stacked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# y_valid is unchanged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/gjb_lab/2472402/miniconda/envs/sandbox/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/gjb_lab/2472402/miniconda/envs/sandbox/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/gjb_lab/2472402/miniconda/envs/sandbox/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/gjb_lab/2472402/miniconda/envs/sandbox/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/gjb_lab/2472402/miniconda/envs/sandbox/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/cluster/gjb_lab/2472402/miniconda/envs/sandbox/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/gjb_lab/2472402/miniconda/envs/sandbox/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for each fold in the 7 fold cross validation procedure, do...\n",
    "for counter, path in enumerate(paths):\n",
    "\n",
    "    counter += 1 # start from 1\n",
    "    \n",
    "    eprint('Commencing fold %d of cross validation at %s'%(counter, datetime.now().strftime(\"%D %H:%M:%S\")))\n",
    "\n",
    "    train_path = path + 'data/'\n",
    "    valid_path = path + 'valid/'\n",
    "    \n",
    "    # get file names ending with .pssm\n",
    "    train_files = [f for f in os.listdir(train_path) if f[-5:] == '.pssm']\n",
    "    valid_files = [f for f in os.listdir(valid_path) if f[-5:] == '.pssm']\n",
    "    \n",
    "    # comment out these lines after dry run\n",
    "    train_files = train_files[0:12]\n",
    "    valid_files = valid_files[0:2]\n",
    "    \n",
    "    # get X_train and X_valid\n",
    "\n",
    "    # read PSSM profiles as numpy arrays\n",
    "    train_pssm = [np.genfromtxt(fname = train_path + fn) for fn in train_files]\n",
    "    valid_pssm = [np.genfromtxt(fname = valid_path + fn) for fn in valid_files]\n",
    "    \n",
    "    # window PSSM profiles get patterns\n",
    "    # layer 1 sliding window flank = 8\n",
    "    X_train = [sliding_window(pssm, flank=8) for pssm in train_pssm]\n",
    "    X_valid = [sliding_window(pssm, flank=8) for pssm in valid_pssm]\n",
    "\n",
    "    # get Y_train and Y_valid\n",
    "    \n",
    "    # remove .pssm extension and convert to int for lookup\n",
    "    train_numbers = [int(fn[:-5]) for fn in train_files] # change to fn[-4:] for HMM\n",
    "    valid_numbers = [int(fn[:-5]) for fn in valid_files] # change to fn[-4:] for HMM\n",
    "    \n",
    "    # lookup seqIDs given jnet number\n",
    "    train_dssp_IDs = [sd[sd.number == num].letters.values[0] for num in train_numbers]\n",
    "    valid_dssp_IDs = [sd[sd.number == num].letters.values[0] for num in valid_numbers]\n",
    "    \n",
    "    # obtain 3-column DSSP of domains given their seqID. See get_dssp() defined above\n",
    "    Y_train = [get_dssp(ID) for ID in train_dssp_IDs]\n",
    "    Y_valid = [get_dssp(ID) for ID in valid_dssp_IDs]\n",
    "\n",
    "    assert all([y.shape[1] == 3 for y in Y_train])\n",
    "    assert all([y.shape[1] == 3 for y in Y_valid])\n",
    "    assert all([x.shape[0] == y.shape[0] for (x, y) in zip(X_train, Y_train)])\n",
    "    assert all([x.shape[0] == y.shape[0] for (x, y) in zip(X_valid, Y_valid)])\n",
    "\n",
    "    # get stacked versions for layer 1 input\n",
    "    X_train_stacked = np.concatenate(tuple(X_train))\n",
    "    X_valid_stacked = np.concatenate(tuple(X_valid))\n",
    "    Y_train_stacked = np.concatenate(tuple(Y_train))\n",
    "    Y_valid_stacked = np.concatenate(tuple(Y_valid))\n",
    "\n",
    "    # sanitys check before passing into model1\n",
    "    assert X_train_stacked.shape[0] == Y_train_stacked.shape[0]\n",
    "    assert X_valid_stacked.shape[0] == Y_valid_stacked.shape[0]\n",
    "    \n",
    "    assert X_train_stacked.shape[1] == 340\n",
    "    assert X_valid_stacked.shape[1] == 340\n",
    "    \n",
    "    assert Y_train_stacked.shape[1] == 3\n",
    "    assert Y_valid_stacked.shape[1] == 3\n",
    "    \n",
    "    assert X_train_stacked.dtype =='float64'\n",
    "    assert X_valid_stacked.dtype == 'float64'\n",
    "    \n",
    "    assert Y_train_stacked.dtype =='float64'\n",
    "    assert Y_valid_stacked.dtype == 'float64'\n",
    "\n",
    "    # sequence to structure layer\n",
    "    model1 = keras.Sequential([\n",
    "        layers.Dense(units = 100, activation ='sigmoid', input_shape=[340]),\n",
    "        layers.Dense(units = 3, activation ='softmax')\n",
    "    ])\n",
    "\n",
    "    model1.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    eprint('Fitting layer 1 model. %s' % datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "    history1 = model1.fit(X_train_stacked, Y_train_stacked,\n",
    "                          validation_data = (X_valid_stacked,Y_valid_stacked),\n",
    "                          batch_size = 128,\n",
    "                          epochs = 300, \n",
    "                          verbose = 0)\n",
    "\n",
    "    eprint('Calculating layer 1 predictions. %s' % datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "    # obtain layer 1 predictions and apply argmax to get 1s and 0s\n",
    "    # do this also for X_valid because X_valid needs to be same shape as X_train\n",
    "    Y_pred_train = [argmax(model1.predict(X)) for X in X_train]\n",
    "    Y_pred_valid = [argmax(model1.predict(X)) for X in X_valid]\n",
    "\n",
    "    # process layer 1 predictions into layer 2 X input\n",
    "    # layer 2 sliding window flank = 9\n",
    "    X_train_2 = [sliding_window(Y, flank = 9) for Y in Y_pred_train]\n",
    "    X_valid_2 = [sliding_window(Y, flank = 9) for Y in Y_pred_valid]\n",
    "    X_train_2_stacked = np.concatenate(tuple(X_train_2))\n",
    "    X_valid_2_stacked = np.concatenate(tuple(X_valid_2))\n",
    "    \n",
    "    # sanity checks before passing into model2\n",
    "    assert X_train_2_stacked.shape[0] == Y_train_stacked.shape[0]\n",
    "    assert X_valid_2_stacked.shape[0] == Y_valid_stacked.shape[0]\n",
    "    \n",
    "    assert X_train_2_stacked.shape[1] == 57\n",
    "    assert X_valid_2_stacked.shape[1] == 57\n",
    "    \n",
    "    assert X_train_stacked.dtype == 'float64'\n",
    "    assert X_valid_stacked.dtype == 'float64'\n",
    "    \n",
    "    # structure to structure layer\n",
    "    model2 = keras.Sequential([\n",
    "        layers.Dense(units=100, activation='sigmoid', input_shape=[57]), \n",
    "        layers.Dense(units=3, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    model2.compile(\n",
    "        optimizer='sgd', \n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    eprint('Fitting layer 2 model. %s' % datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "    history2 = model2.fit(\n",
    "        X_train_2_stacked, Y_train_stacked, # y_train is unchanged\n",
    "        validation_data = (X_valid_2_stacked, Y_valid_stacked), # y_valid is unchanged\n",
    "        batch_size = 128, \n",
    "        epochs = 300, \n",
    "        verbose = 0 \n",
    "    )\n",
    "\n",
    "    # save results \n",
    "    eprint('Saving results to %s' % out_path)\n",
    "\n",
    "    history = [pd.DataFrame(history1.history), pd.DataFrame(history2.history)]\n",
    "    pickle.dump(history, open(out_path + 'results_%d.pkl' % counter, 'wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    model1.save(out_path + 'fold%d_model1' % counter, save_format = 'tf') # tensorflow SavedModel format\n",
    "    model2.save(out_path + 'fold%d_model2' % counter, save_format = 'tf')\n",
    "\n",
    "    # finish current fold\n",
    "    eprint('Finished fold %d of cross validation at %s\\n' % (counter, datetime.now().strftime(\"%D %H:%M:%S\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "sandbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

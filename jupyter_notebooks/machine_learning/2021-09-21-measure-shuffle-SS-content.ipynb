{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97126771-b720-46b1-8991-22775e31f37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/cluster/gjb_lab/2472402/ml-env/bin/python\n",
    "#$ -jc short\n",
    "#$ -pe smp 16\n",
    "#$ -mods l_hard mfree 16G\n",
    "#$ -cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c19da12-7bb1-4914-be52-9ada87cb669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "from os import path\n",
    "import glob\n",
    "import random\n",
    "import pickle\n",
    "from joblib import Memory\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "cachedir = './cachedir'\n",
    "memory = Memory(cachedir,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c54ff3d-06a1-4ad5-b9d6-66055cd18688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splits(resume_log_file):\n",
    "    val_splits = []\n",
    "    set_idx = -1\n",
    "    cur_set = set() \n",
    "    with open(resume_log_file,'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('#SET'):\n",
    "                if set_idx > -1:\n",
    "                    val_splits.append(cur_set)\n",
    "                    cur_set = set()\n",
    "                set_idx += 1\n",
    "            else:\n",
    "                seqID = int(line.split('/')[-1].replace('.pssm',''))\n",
    "                cur_set.add(seqID)\n",
    "        # append last set which is not followed by another line '#SET...'\n",
    "        val_splits.append(cur_set)\n",
    "    assert sum([len(s) for s in val_splits])==1348\n",
    "    return val_splits\n",
    "\n",
    "def read_sec_df():\n",
    "    df = pd.read_csv('/cluster/gjb_lab/2472402/data/1507_sec.csv',names=['seqID','domain','sec'])\n",
    "    return df\n",
    "\n",
    "@memory.cache\n",
    "def sec_to_arr(sec_string):\n",
    "    res = np.empty(shape=(len(sec_string),3))\n",
    "    res[:] = np.nan\n",
    "    for i in range(0,len(sec_string)):\n",
    "        if sec_string[i:i+1] == 'H':\n",
    "            res[i] = np.array([0,1,0])\n",
    "        else:\n",
    "            if sec_string[i:i+1] == 'E' or sec_string[i:i+1] == 'B':\n",
    "                res[i] = np.array([1,0,0])\n",
    "            else:\n",
    "                assert sec_string[i:i+1] != None\n",
    "                res[i] = np.array([0,0,1])\n",
    "    assert not np.isnan(np.sum(res))\n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "\n",
    "@memory.cache\n",
    "def build_cache():\n",
    "    cache = {}\n",
    "    sec_df = read_sec_df()\n",
    "    for i,row in sec_df.iterrows():\n",
    "        cache[row.seqID] = sec_to_arr(row.sec)\n",
    "    assert len(cache) == 1507\n",
    "    return cache\n",
    "\n",
    "def get_content_df_from_file(resume_log_file):\n",
    "    df = read_sec_df()\n",
    "    kf = get_splits(resume_log_file)\n",
    "    content_df = []\n",
    "    for i,idxs in enumerate(kf):\n",
    "        arr = list(map(lambda s: sec_to_arr(s), df[df.seqID.isin(idxs)].sec))\n",
    "        arr = pd.concat(arr)\n",
    "        E, H, C = arr.sum(axis=0)/len(arr) * 100\n",
    "        content_df.append([i,H,E,C])\n",
    "    \n",
    "    return pd.DataFrame(content_df,columns=['Fold','Helix','Sheet','Coil'])\n",
    "\n",
    "\n",
    "def check_df(df,threshold):\n",
    "    H = df.loc[7,'Helix']\n",
    "    E = df.loc[7,'Sheet']\n",
    "    C = df.loc[7,'Coil']\n",
    "    return H < threshold and E < threshold and C < threshold    \n",
    "\n",
    "\n",
    "def split_list(ls):\n",
    "    res = []\n",
    "    k = int(np.ceil(len(ls)/7))\n",
    "    idxs = range(0,len(ls),k)\n",
    "    \n",
    "    for i in idxs:\n",
    "        res.append(ls[i:i+k])\n",
    "\n",
    "    return res\n",
    "\n",
    "def get_best_split(threshold):\n",
    "    \n",
    "    seqIDs = [int(f.split('/')[-1][:-5]) for f in glob.glob('/cluster/homes/adrozdetskiy/Projects/jpredJnet231ReTrainingSummaryTable/scores/training/*.pssm')]\n",
    "    \n",
    "    cache = build_cache()\n",
    "    \n",
    "    def get_content_df():\n",
    "        content_df = []\n",
    "        splits = split_list(seqIDs)\n",
    "        for i,split in enumerate(splits):\n",
    "            arr = [cache[seqID] for seqID in split]\n",
    "            arr = pd.concat(arr)\n",
    "            E, H, C = arr.sum(axis=0)/len(arr) * 100\n",
    "            content_df.append([i,H,E,C])\n",
    "        content_df = pd.DataFrame(content_df,columns=['Fold','Helix','Sheet','Coil'])\n",
    "        dH =  content_df.Helix.max() - content_df.Helix.min()\n",
    "        dE =  content_df.Sheet.max() - content_df.Sheet.min()\n",
    "        dC = content_df.Coil.max() - content_df.Coil.min()\n",
    "        content_df.loc[len(content_df)] = [7,dH,dE,dC]\n",
    "        return splits,content_df\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    while True:\n",
    "        i += 1\n",
    "        random.shuffle(seqIDs)\n",
    "        splits,content_df = get_content_df()\n",
    "        if check_df(content_df, threshold):\n",
    "            break\n",
    "    \n",
    "    print(f'Done. Took {i} iterations to find a shuffle with threshold of {threshold}')\n",
    "    \n",
    "    return splits,content_df\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414b19f1-3f9a-4ab4-9dbb-5e75928e7526",
   "metadata": {},
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ff2c337-20c2-4b87-9315-e14accf554ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Took 62 iterations to find a shuffle with threshold of 2\n"
     ]
    }
   ],
   "source": [
    "threshold = 1.1\n",
    "\n",
    "splits,df = get_best_split(threshold)\n",
    "\n",
    "with open('shuffle_%s.pkl' % str(threshold),'wb') as f:\n",
    "    pickle.dump((splits,df),f,protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ml-env)",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
